#!/usr/bin/python3

import os
import re
import pwd
import sys
import json
import time
import argparse
import TADA
import logging

from threading import Thread, Event

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, LDMSDContainer, process_args, \
                      add_common_args, jprint, parse_ldms_ls, \
                      ldmsd_version

if __name__ != "__main__":
    raise RuntimeError("This should not be impoarted as a module.")

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())

def dprompt(msg):
    """Show prompt if TADA.DEBUG flag (`--debug` CLI option) is set"""
    return
    if TADA.DEBUG and sys.flags.interactive:
        input(msg)

#### argument parsing #### -------------------------------------------
ap = argparse.ArgumentParser(description = "store_app test." )
add_common_args(ap)
ap.add_argument("--slurm-notifier", type = str,
                default = "__find_from_prefix__",
                help = "The path (in container) to slurm_notifier library." )
ap.add_argument("--num-compute", type = int,
                default = 2,
                help = "Number of compute nodes.")
args = ap.parse_args()
process_args(args)

#### config variables #### ------------------------------
USER = args.user
PREFIX = args.prefix
COMMIT_ID = args.commit_id
SRC = args.src
CLUSTERNAME = args.clustername
DB = args.data_root
NUM_COMPUTE = args.num_compute
LDMSD_VERSION = ldmsd_version(PREFIX)
SCRIPT_DIR = os.path.realpath(sys.path[0])

CONT_PYTHON = "/usr/bin/python3" if LDMSD_VERSION >= (4, 100, 0) else "/usr/bin/python2"

STORE_ROOT = "/store" # path inside container (agg-2)

SLURM_NOTIFIER = args.slurm_notifier
if SLURM_NOTIFIER == "__find_from_prefix__":
    paths = map(lambda x: "{}/{}/ovis-ldms/libslurm_notifier.so"\
                          .format(PREFIX, x),
                ["lib", "lib64"])
    for p in paths:
        if os.path.exists(p):
            SLURM_NOTIFIER = p.replace(PREFIX, '/opt/ovis', 1)
            break
    else:
        raise RuntimeError("libslurm_notifier.so not found")

#### spec #### -------------------------------------------------------
common_plugin_config = [
        "component_id=%component_id%",
        "instance=%hostname%/%plugin%",
        "producer=%hostname%",
    ]
spec = {
    "name" : CLUSTERNAME,
    "description" : "{}'s test_agg_slurm cluster".format(USER),
    "type" : "NA",
    "templates" : { # generic template can apply to any object by "!extends"
        "compute-node" : {
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "slurmd",
                    "!extends" : "slurmd",
                },
                {
                    "name" : "sampler-daemon",
                    "!extends" : "ldmsd-sampler",
                },
            ],
        },
        "slurmd" : {
            "type" : "slurmd",
            "plugstack" : [
                {
                    "required" : True,
                    "path" : SLURM_NOTIFIER,
                    "args" : [
                        "auth=none",
                        "port=10000",
                        "client=sock:localhost:10000:none",
                    ],
                },
            ],
        },
        "sampler_plugin" : {
            "interval" : 1000000,
            "offset" : 0,
            "config" : common_plugin_config,
            "start" : True,
        },
        "ldmsd-base" : {
            "type" : "ldmsd",
            "listen_port" : 10000,
            "listen_xprt" : "sock",
            "listen_auth" : "none",
        },
        "ldmsd-sampler" : {
            "!extends" : "ldmsd-base",
            "samplers" : [
                {
                    "plugin" : "app_sampler",
                    "!extends" : "sampler_plugin",
                },
            ],
        },
        "prdcr" : {
            "host" : "%name%",
            "port" : 10000,
            "xprt" : "sock",
            "type" : "active",
            "interval" : 1000000,
        },
        "ldmsd-aggregator" : {
            "!extends" : "ldmsd-base",
            "config" : [ # additional config applied after prdcrs
                "prdcr_start_regex regex=.*",
                "updtr_add name=all interval=1000000 offset=%offset%",
                "updtr_prdcr_add name=all regex=.*",
                "updtr_start name=all"
            ],
        },
    }, # templates
    "nodes" : [
        {
            "hostname" : "node-{}".format(i),
            "component_id" : 10000 + i,
            "!extends" : "compute-node",
        } for i in range(1, NUM_COMPUTE+1)
    ] + [
        {
            "hostname" : "agg-1{}".format(j),
            "!extends" : "compute-node",
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "agg",
                    "!extends" : "ldmsd-aggregator",
                    "offset" : 200000,
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "node-{}".format(i*2+j),
                            "!extends" : "prdcr",
                        } for i in range(0, int(NUM_COMPUTE / 2))
                    ],
                },
            ]
        } for j in [1, 2]
    ] + [
        {
            "hostname" : "agg-2",
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "aggregator",
                    "!extends" : "ldmsd-aggregator",
                    "offset" : 400000,
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "agg-1{}".format(i),
                            "!extends" : "prdcr",
                        } for i in [1,2]
                    ],
                    # additional config applied after prdcrs
                    "config" : [
                        # -- for v5 --
                        "load name=app_store plugin=store_app",
                        "config name=app_store path={}/store_app".format(STORE_ROOT),
                        "strgp_add name=app_strgp" \
                                 " container=app_store schema=app_sampler",
                        "strgp_prdcr_add name=app_strgp regex=.*",
                        "strgp_start name=app_strgp",

                        "prdcr_start_regex regex=.*",
                        "updtr_add name=all interval=1000000 offset=%offset%",
                        "updtr_prdcr_add name=all regex=.*",
                        "updtr_start name=all",
                    ] if LDMSD_VERSION >= (4, 100, 0) else [
                        # -- for v4 --
                        "load name=store_app",
                        "config name=store_app path={}".format(STORE_ROOT),
                        "strgp_add name=app_strgp plugin=store_app" \
                                 " container=store_app schema=app_sampler",
                        "strgp_prdcr_add name=app_strgp regex=.*",
                        "strgp_start name=app_strgp",

                        "prdcr_start_regex regex=.*",
                        "updtr_add name=all interval=1000000 offset=%offset%",
                        "updtr_prdcr_add name=all regex=.*",
                        "updtr_start name=all",
                    ],
                },
            ],
        },
        {
            "hostname" : "headnode",
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "slurmctld",
                    "type" : "slurmctld",
                },
            ]
        },
    ], # nodes

    #"image": "ovis-centos-build:slurm",
    "cpu_per_node": 2,
    "slurm_loglevel" : "debug2",
    "oversubscribe" : "FORCE",
    "cap_add": [ "SYS_PTRACE", "SYS_ADMIN" ],
    "image": args.image,
    "ovis_prefix": PREFIX,
    "env" : { "FOO": "BAR" },
    "mounts": [
        "{}:/db:rw".format(DB),
    ] + args.mount +
    ( ["{0}:{0}:ro".format(SRC)] if SRC else [] ),
}

#### test definition ####

test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "store_app_test",
                 test_desc = "store_app plugin test in a virtual SLURM cluster",
                 test_user = args.user,
                 commit_id = COMMIT_ID,
                 tada_addr = args.tada_addr)
test.add_assertion(1, "Verify data")

#### Helping Functions ####

def cleanup_db(cluster):
    cont = cluster.get_container("headnode")
    LST = [ "job.sh", "jobpapi.json", "prog", "prog.c", "slurm*.out", "syspapi.json" ]
    LST = [ "/db/{}".format(x) for x in LST ]
    LST += [ "{}/{}".format(STORE_ROOT, x) for x in ["store_app"] ]
    cont = cluster.get_container("agg-2")
    cont.exec_run("rm -rf {}".format(" ".join(LST)))

def metric_value_wrap(value):
    if type(value) == list:
        return tuple(value)
    if type(value) == str:
        return value.split('\x00', 1)[0] # strip null bytes
    return value

def sos_query(dcont, sos_cont, sos_schema, sos_index):
    global CONT_PYTHON
    rc, out = dcont.exec_run("/db/sos_query.py -C {} -S {} -X {}"\
                             .format(sos_cont, sos_schema, sos_index))
    if rc != 0:
        raise RuntimeError("sos_query error {}, out: {}".format(rc, out))
    data = json.loads(out)
    _const = lambda x: tuple(x) if type(x) == list else x
    _data = [ ( float(d['timestamp'][0])+1e-6*float(d['timestamp'][1]),
                d['component_id'],
                d['job_id'],
                d['rank'],
                metric_value_wrap(d[sos_schema]) ) for d in data ]
    return _data

def ldms_ls(host, port):
    global cluster
    rc, out = cluster.ldms_ls("-h", host, "-p", str(port), "-l", "-v")
    return parse_ldms_ls(out)

################################################################################

#### Start! ####
test.start()

log.info("-- Get or create the cluster --")
cluster = LDMSDCluster.get(spec["name"], create = True, spec = spec)
cluster.all_exec_run("pkill ldmsd")
cleanup_db(cluster)

cont = cluster.get_container("headnode")
agg2 = cluster.get_container("agg-2")

cont.write_file("/db/sos_query.py", open(SCRIPT_DIR + "/sos_query.py").read())
cont.exec_run("chmod 755 /db/sos_query.py")

log.info("-- Preparing job script & programs --")
code = """\
#include <stdio.h>
#include <unistd.h>

int main(int argc, char **argv)
{
    int n = 4096, N = 5;
    int sum, i, j;
    for (j = 0; j < N; j++) {
        sum = 0;
        for (i = 0; i < n; i++) {
            sum += i;
        }
        printf("sum: %d\\n", sum);
        sleep(1);
    }
    return 0;
}
"""
cont.write_file("/db/prog.c", code)

rc, out = cont.exec_run("gcc -o /db/prog /db/prog.c")
assert(rc == 0)

code = """\
#!/bin/bash

#SBATCH -n 2
#SBATCH -D /db

srun /db/prog
"""
cont.write_file("/db/job.sh", code)

log.info("-- Start daemons --")
cluster.start_daemons()
cluster.make_known_hosts()

log.info("... wait a bit to make sure ldmsd's are up")
time.sleep(5)

cont = cluster.get_container("headnode")

dprompt("Press ENTER to submit jobs")

# Spawn another thread to collect LDMS data for verification

class LDMS_LS_Thread(Thread):
    """A thread to periodically `ldms_ls`"""
    def __init__(self, name = "ldms_ls_thread", cluster = None,
                 interval = 1, offset = 0.8):
        super(LDMS_LS_Thread, self).__init__(name = name)
        self.cluster = cluster
        self._stop_ev = Event()
        self.interval = interval
        self.offset = offset
        self.records = []

    def run(self): # thread procedure
        while not self._stop_ev.isSet():
            result = ldms_ls("agg-2", 10000)
            for data in result.values():
                if 'C' not in data['meta']['flags']:
                    continue
                self.records.append(data)
            now = time.time()
            wakeup = now + self.interval
            wakeup = int(wakeup / self.interval)*self.interval + self.offset
            self._stop_ev.wait(wakeup - now) # wait until timeout or ev set

    def stop(self):
        self._stop_ev.set()

    def get_records(self, metric_name):
        # ts, comp, job_id, rank, metric_value
        _ret = []
        for rec in self.records:
            ts = float(rec['meta']['update'])
            _data = rec['data']
            comp_id = _data['component_id']
            job_id  = _data['job_id']
            rank    = _data['task_rank']
            val     = _data[metric_name]
            vtype   = rec['data_type'][metric_name]
            if type(val) == list:
                val = tuple(val)
            if vtype == 'char':
                val = val.encode()[0]   # convert to int -- a work around b/c
                                        # sos does not have CHAR type
            ent = (ts, comp_id, job_id, rank, val)
            _ret.append(ent)
        return _ret

    def get_metric_names(self):
        names = set(self.records[0]['data'].keys())
        names -= set(["component_id", "job_id", "app_id", "task_rank"])
        return names

# NOTE oversampling ldms_ls b/c we don't want to miss any data
thr = LDMS_LS_Thread(interval=0.25, offset=0)
thr.start()

log.info("-- Submitting jobs --")
job_one = cluster.sbatch("/db/job.sh")
log.info("job_one: {}".format(job_one))
time.sleep(5)
job_two = cluster.sbatch("/db/job.sh")
log.info("job_two: {}".format(job_two))

dprompt("Press ENTER to timed-wait jobs (Ctrl-C to debug)")
# wait 10 sec or until all jobs are done
timeout = 60 + time.time()
while time.time() < timeout and cluster.squeue():
    time.sleep(2)

time.sleep(2)
thr.stop()

dprompt("Press ENTER to kill ldmsd")
cluster.all_exec_run("pkill ldmsd")

log.info("Verifying data ...")
# test.add_assertion(1, "Verify data")
for mname in thr.get_metric_names():
    sdata = set(sos_query(agg2, "/store/store_app", mname, "time_job"))
    ldata = set(thr.get_records(mname))
    if not sdata:
        test.assert_test(1, False, "store data empty for '{}'".format(mname))
    if ldata < sdata:
        test.assert_test(1, False, "{} < {}".format(ldata, sdata))
else:
    test.assert_test(1, True, "sos data is not empty and sos data < ldms_ls data")

test.finish()

dprompt("Press ENTER to REMOVE the cluster, or Ctrl-C to debug")
cluster.remove()
